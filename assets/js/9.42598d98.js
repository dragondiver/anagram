(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{407:function(t,a,e){"use strict";e.r(a);var s=e(56),n=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"discussions"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#discussions"}},[t._v("#")]),t._v(" Discussions")]),t._v(" "),e("h2",{attrs:{id:"maintainability"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#maintainability"}},[t._v("#")]),t._v(" Maintainability")]),t._v(" "),e("p",[t._v("There are few dependencies, so to keep them updated should be easy.\nIn Github i configured Dependabot alerts, to get warnings on outdated or unsecure dependencies")]),t._v(" "),e("p",[t._v("The CodeQL actions in Github do checks for the following java versions:")]),t._v(" "),e("div",{staticClass:"language-yaml extra-class"},[e("pre",{pre:!0,attrs:{class:"language-yaml"}},[e("code",[e("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("strategy")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fail-fast")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("matrix")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("java-version")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" 8.0.192"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" 11.0.3"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("17")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" 18"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("ea "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),e("p",[t._v("The reduction to just a few classes should ensure maintainability")]),t._v(" "),e("h2",{attrs:{id:"scalability"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#scalability"}},[t._v("#")]),t._v(" Scalability")]),t._v(" "),e("p",[t._v("The current implementation was testet with 11.794.300 words without problems on a MacBook Air M1 / 8GB Ram\nFor bigger files one would use a database, so we do not have to keep the Concurrent HashMap in memory.\nImplementation of AnagramStorage would have to change, or you could at another CDI Alternative and inject it using either:")]),t._v(" "),e("ul",[e("li",[t._v("@Named")]),t._v(" "),e("li",[t._v("@Produces")]),t._v(" "),e("li",[t._v("Custom Qualifiers")])]),t._v(" "),e("p",[t._v("If you would like to scale in number of processes, one would need a UUID to identify the AnagramContiners in the DB")]),t._v(" "),e("h2",{attrs:{id:"performance"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#performance"}},[t._v("#")]),t._v(" Performance")]),t._v(" "),e("p",[t._v("As pointed out in "),e("RouterLink",{attrs:{to:"/exploration/"}},[t._v("Exploration")]),t._v(" i did a day of exploration into performance considerations.\nObviously, processor and more memory would increase performance to a point.\nIf you gad large files, you could also think about splitting the tasks up into portions, for example partitioning the data by word length. All Anagrams definitely should have the same word length. And then do some parallel processing.")],1)])}),[],!1,null,null,null);a.default=n.exports}}]);